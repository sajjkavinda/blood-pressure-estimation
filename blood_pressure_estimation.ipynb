{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVzGjUxnEBcyyJj1W3CdxK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajjkavinda/blood-pressure-estimation/blob/main/blood_pressure_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notebook** **Preparation**"
      ],
      "metadata": {
        "id": "ttx3r3H7-UQ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D90HpRH--N92"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile\n",
        "from scipy.signal import stft\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import learning_curve"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl"
      ],
      "metadata": {
        "id": "3FxXd91z-R2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aP7Qs2V8-f_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Preparation**"
      ],
      "metadata": {
        "id": "_AhyyteP-jvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract the dataset zip\n",
        "zip_path = \"/content/drive/MyDrive/PCG+BP-Dataset/Dataset_PCG_signals.zip\"\n",
        "extract_dir = \"/content/pcg_bp_dataset\"\n",
        "\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(\"Directory contents:\", os.listdir(extract_dir))"
      ],
      "metadata": {
        "id": "YlOGgZXL-sRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#List the reference csv files\n",
        "data_dir = \"/content/pcg_bp_dataset/Dataset_PCG_signals copy\"\n",
        "\n",
        "#Load BP labels\n",
        "bp_file = os.path.join(data_dir, \"Participant_BP_Label.xlsx\")\n",
        "df_bp = pd.read_excel(bp_file)\n",
        "print(\"BP labels head:\")\n",
        "print(df_bp.head())\n",
        "\n",
        "#Load demographics for each patient\n",
        "info_file = os.path.join(data_dir, \"Information_78_participant.xlsx\")\n",
        "df_info = pd.read_excel(info_file)\n",
        "print(\"Demographics head:\")\n",
        "print(df_info.head())"
      ],
      "metadata": {
        "id": "WB2VCPm2-u6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Primary key\n",
        "key_col = \"filename\"\n",
        "\n",
        "df_meta = pd.merge(df_bp, df_info, on=key_col)\n",
        "print(df_meta.head())\n",
        "print(df_meta.shape)\n",
        "\n",
        "# Paths\n",
        "root_path = \"/content/pcg_bp_dataset/Dataset_PCG_signals copy\"\n",
        "bandpass_path = os.path.join(root_path, \"Bandpass_signal\", \"78_participants_BPF_7_segment\")\n",
        "original_11seg_path = os.path.join(root_path, \"Original_signal\", \"78_participants_11_segment\")\n",
        "original_7seg_path = os.path.join(root_path, \"Original_signal\", \"78_participants_7_segment\")\n",
        "original_full_path = os.path.join(root_path, \"Original_signal\", \"Original_78_participants\")"
      ],
      "metadata": {
        "id": "adeNxM3T-xVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MAP the two CSV files and the folders to be used in the training\n",
        "\n",
        "#BP files\n",
        "bp_file = os.path.join(root_path, \"Participant_BP_Label.xlsx\")\n",
        "bp_df = pd.read_excel(bp_file, header=0)\n",
        "bp_df.columns = bp_df.columns.str.strip()\n",
        "print(\"BP columns:\", bp_df.columns)\n",
        "\n",
        "#Demographics files\n",
        "demo_file = os.path.join(root_path, \"Information_78_participant.xlsx\")\n",
        "demo_df = pd.read_excel(demo_file, header=0)\n",
        "demo_df.columns = demo_df.columns.str.strip()\n",
        "print(\"Demographics columns:\", demo_df.columns)\n",
        "\n",
        "#Mapping dictionories\n",
        "bp_map = {row['filename'].lower(): {'systolic': row['SYS'], 'diastolic': row['DAI']}\n",
        "          for _, row in bp_df.iterrows()}\n",
        "\n",
        "demo_map = {row['filename'].lower(): {'age': row['age'], 'gender': row['gender'],\n",
        "                                      'pluse': row['pluse'], 'PtP': row['PtP'],\n",
        "                                      'W': row['W'], 'H': row['H']}\n",
        "            for _, row in demo_df.iterrows()}\n",
        "\n",
        "#Find each signal data in WAV format\n",
        "def get_wav_files(folder):\n",
        "    wavs = []\n",
        "    for root, dirs, files in os.walk(folder):\n",
        "        for f in files:\n",
        "            if f.lower().endswith('.wav'):\n",
        "                wavs.append(os.path.join(root, f))\n",
        "    return wavs\n",
        "\n",
        "#Build a dataframe from WAV files and dictionories\n",
        "def build_df(wav_list, bp_map, demo_map, segment_type=\"Bandpass\"):\n",
        "    data = []\n",
        "    for wav_path in wav_list:\n",
        "        fname = os.path.basename(wav_path).lower()\n",
        "        parent_folder = os.path.basename(os.path.dirname(wav_path)).lower()\n",
        "\n",
        "        participant_num = ''.join(filter(str.isdigit, parent_folder))\n",
        "        excel_fname = f\"participant_{participant_num}.wav\"\n",
        "\n",
        "        bp_info = bp_map.get(excel_fname, None)\n",
        "        demo_info = demo_map.get(fname, None)\n",
        "\n",
        "        data.append({\n",
        "            \"filename\": fname,\n",
        "            \"wav_path\": wav_path,\n",
        "            \"bp_filename\": excel_fname,\n",
        "            \"systolic\": bp_info['systolic'] if bp_info else None,\n",
        "            \"diastolic\": bp_info['diastolic'] if bp_info else None,\n",
        "            \"age\": demo_info['age'] if demo_info else None,\n",
        "            \"gender\": demo_info['gender'] if demo_info else None,\n",
        "            \"pluse\": demo_info['pluse'] if demo_info else None,\n",
        "            \"PtP\": demo_info['PtP'] if demo_info else None,\n",
        "            \"W\": demo_info['W'] if demo_info else None,\n",
        "            \"H\": demo_info['H'] if demo_info else None,\n",
        "            \"segment_type\": segment_type\n",
        "        })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "#Use the functions for each folder contains signal data\n",
        "bandpass_wavs = get_wav_files(bandpass_path)\n",
        "orig11_wavs = get_wav_files(original_11seg_path)\n",
        "orig7_wavs = get_wav_files(original_7seg_path)\n",
        "full_wavs = get_wav_files(original_full_path)\n",
        "\n",
        "#Use the function to build the dataframe\n",
        "df_bandpass = build_df(bandpass_wavs, bp_map, demo_map, segment_type=\"Bandpass\")\n",
        "df_orig11 = build_df(orig11_wavs, bp_map, demo_map, segment_type=\"Original_11\")\n",
        "df_orig7 = build_df(orig7_wavs, bp_map, demo_map, segment_type=\"Original_7\")\n",
        "df_full = build_df(full_wavs, bp_map, demo_map, segment_type=\"Original_Full\")\n",
        "\n",
        "#Combine all to be used in the pipeline\n",
        "combined_df = pd.concat([df_bandpass, df_orig11, df_orig7, df_full], ignore_index=True)\n",
        "\n",
        "combined_df[['age','gender','pluse','PtP','W','H']] = combined_df.apply(\n",
        "    lambda row: pd.Series(demo_map.get(row['bp_filename'].lower(), {\n",
        "        'age': None, 'gender': None, 'pluse': None, 'PtP': None, 'W': None, 'H': None\n",
        "    })), axis=1\n",
        ")\n",
        "\n",
        "print(combined_df.head(10))\n",
        "print(\"Total WAV entries:\", len(combined_df))"
      ],
      "metadata": {
        "id": "o7M1joEA-zdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Extraction**"
      ],
      "metadata": {
        "id": "njVj1PT0_N9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature extraction using STFT\n",
        "#Learning source: https://www.mathworks.com/help/signal/ref/stft.html\n",
        "#Used chatgpt tool to understand and experiment the best way to use STFT for this study\n",
        "def extract_stft_features(wav_path, nperseg=256):\n",
        "    sr, y = wavfile.read(wav_path)\n",
        "    y = y.astype(float)\n",
        "    f, t, Zxx = stft(y, fs=sr, nperseg=nperseg)\n",
        "    power = np.abs(Zxx)**2\n",
        "    features = {\n",
        "        'stft_mean': np.mean(power),\n",
        "        'stft_std': np.std(power),\n",
        "        'stft_max': np.max(power),\n",
        "        'stft_median': np.median(power)\n",
        "    }\n",
        "    return features\n",
        "\n",
        "#Apply the feature extraction function to the dataframe\n",
        "stft_features_list = []\n",
        "\n",
        "for path in combined_df['wav_path']:\n",
        "    feats = extract_stft_features(path)\n",
        "    stft_features_list.append(feats)\n",
        "\n",
        "stft_df = pd.DataFrame(stft_features_list)\n",
        "\n",
        "#Combine final dataframe\n",
        "final_df = pd.concat([combined_df.reset_index(drop=True), stft_df], axis=1)\n",
        "\n",
        "print(final_df.head())\n",
        "print(\"Final shape:\", final_df.shape)"
      ],
      "metadata": {
        "id": "tY4cVOFW_Uxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Features and targets\n",
        "features = final_df[['age','gender','pluse','PtP','W','H','stft_mean','stft_std','stft_max','stft_median']]\n",
        "features['gender'] = features['gender'].astype(int)\n",
        "\n",
        "X = features.values\n",
        "y = final_df['systolic'].values\n",
        "\n",
        "#Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "#Split the dataset into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Q7j9amjU_a7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Customize the models to be used in the pipeline**"
      ],
      "metadata": {
        "id": "YaAUW70s_cni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training models\n",
        "\n",
        "#Ridge Regression\n",
        "ridge_reg = Ridge(\n",
        "    alpha=3.0,\n",
        "    solver='cholesky',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "#Lasso Regression\n",
        "lasso_reg = Lasso(\n",
        "    selection=\"cyclic\",\n",
        "    alpha=0.1,\n",
        "    max_iter=20000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "#Support Vector Regression\n",
        "svr_reg = SVR(\n",
        "    kernel='rbf',\n",
        "    C=120,\n",
        "    gamma=\"scale\",\n",
        "    epsilon=2.0\n",
        ")\n",
        "\n",
        "#Decision Tree Regressor\n",
        "dt_reg = DecisionTreeRegressor(\n",
        "    max_depth=9,\n",
        "    min_samples_split=8,\n",
        "    min_samples_leaf=4,\n",
        "    ccp_alpha=0.0005,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "#Gaussian Process Regressor\n",
        "gpr_kernel = (\n",
        "    C(1.0, (1e-2, 1e3)) *\n",
        "    RBF(\n",
        "        length_scale=0.5,\n",
        "        length_scale_bounds=(1e-3, 1e3)\n",
        "    )\n",
        ") + WhiteKernel(\n",
        "    noise_level=1e-3,\n",
        "    noise_level_bounds=(1e-5, 1e1)\n",
        ")\n",
        "\n",
        "gpr_reg = GaussianProcessRegressor(\n",
        "    kernel=gpr_kernel,\n",
        "    alpha=0.0,\n",
        "    normalize_y=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "models = {\n",
        "    'Ridge Regression': ridge_reg,\n",
        "    'Lasso Regression': lasso_reg,\n",
        "    'Support Vector Regression': svr_reg,\n",
        "    'Decision Tree Regressor': dt_reg,\n",
        "    'Gaussian Process Regressor': gpr_reg\n",
        "}"
      ],
      "metadata": {
        "id": "LtbUUfHd_lc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and test**"
      ],
      "metadata": {
        "id": "3EyvpAoG_yDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train and test\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    results.append({'Model': name, 'MSE': mse, 'R2': r2})\n",
        "    print(f\"{name} --> MSE: {mse:.2f}, R2: {r2:.2f}\")\n",
        "\n",
        "#Results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nSummary of model performance:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "hUwvpso7_1YV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning Curve Analysis**"
      ],
      "metadata": {
        "id": "pKlXzd2OqmZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Learning Curve Analysis\n",
        "def plot_learning_curve(model, X, y, model_name, cv=5, scoring='neg_mean_squared_error'):\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        model,\n",
        "        X, y,\n",
        "        cv=cv,\n",
        "        scoring=scoring,\n",
        "        train_sizes=np.linspace(0.1, 1.0, 6),\n",
        "        n_jobs=-1,\n",
        "        shuffle=True,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    train_scores_mean = -np.mean(train_scores, axis=1)\n",
        "    test_scores_mean  = -np.mean(test_scores, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', label=\"Training MSE\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', label=\"Validation MSE\")\n",
        "    plt.title(f\"Learning Curve: {model_name}\")\n",
        "    plt.xlabel(\"Training Examples\")\n",
        "    plt.ylabel(\"Mean Squared Error\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n=== Learning Curve for {name} ===\")\n",
        "    plot_learning_curve(model, X, y, name)"
      ],
      "metadata": {
        "id": "3HWF7wVo8qKf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}